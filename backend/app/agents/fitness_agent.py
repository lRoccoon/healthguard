"""
Fitness Agent - Handles activity analysis and exercise recommendations.
Uses LLM for intelligent analysis when available.
"""

from typing import Dict, Any, Optional, AsyncGenerator
from datetime import datetime
from .base_agent import BaseAgent


class FitnessAgent(BaseAgent):
    """
    Fitness Agent specialized in activity analysis and exercise planning for insulin resistance.
    """

    def __init__(self):
        system_prompt = """You are a Fitness Agent for HealthGuard AI, specializing in exercise for insulin resistance (IR).

Your expertise includes:
- Analyzing HealthKit data (steps, heart rate, active energy)
- Evaluating exercise intensity and duration
- Providing personalized workout recommendations
- Encouraging consistent physical activity

Key principles for IR exercise:
1. Aim for 150+ minutes/week of moderate activity
2. Combination of aerobic + resistance training is ideal
3. Post-meal walks are highly effective for glucose control
4. Consistency > intensity (regular moderate exercise > occasional intense)
5. Monitor heart rate: target 50-70% max HR for moderate activity
6. Avoid excessive cardio without resistance training

Activity targets:
- Steps: 8,000-10,000 per day
- Active energy: 400-600 kcal per day
- Exercise minutes: 30-60 per day

When analyzing activity:
- Celebrate progress, even small wins
- Provide specific, achievable next steps
- Consider user's fitness level and constraints
- Emphasize the metabolic benefits for IR

Always respond in the same language as the user's message.
Always be encouraging and positive!
"""
        super().__init__("FitnessAgent", system_prompt)

    async def process_request(
        self,
        user_message: str,
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Process fitness-related request.
        """
        if self._llm_provider is not None:
            return await self._process_with_llm(user_message, context)

        # Fallback to template-based response
        analysis = await self._analyze_activity(user_message, context)
        recommendations = await self._generate_exercise_plan(analysis, context)
        response = self._format_response(analysis, recommendations)

        return {
            "agent": "fitness",
            "response": response,
            "analysis": analysis,
            "recommendations": recommendations,
            "timestamp": datetime.now().isoformat()
        }

    async def _process_with_llm(
        self,
        user_message: str,
        context: Optional[Dict[str, Any]],
    ) -> Dict[str, Any]:
        """Process using LLM."""
        context_str = self.format_context(context)
        prompt = user_message
        if context_str:
            prompt = f"{context_str}\n\n{user_message}"

        llm_response = await self.call_llm(
            messages=[
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
        )

        return {
            "agent": "fitness",
            "response": llm_response,
            "timestamp": datetime.now().isoformat()
        }

    async def process_request_stream(
        self,
        user_message: str,
        context: Optional[Dict[str, Any]] = None
    ) -> AsyncGenerator[str, None]:
        """
        Process fitness-related request with streaming output.

        Args:
            user_message: User's message about fitness
            context: Context including user history and health data

        Yields:
            str: Tokens from the LLM response
        """
        # If LLM not configured, fallback to non-streaming
        if self._llm_provider is None:
            result = await self.process_request(user_message, context)
            yield result["response"]
            return

        # Build prompt with context
        context_str = self.format_context(context)
        prompt = user_message
        if context_str:
            prompt = f"{context_str}\n\n{user_message}"

        # Stream tokens from LLM
        async for token in self.call_llm_stream(
            messages=[
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
        ):
            yield token

    async def _analyze_activity(
        self,
        message: str,
        context: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Analyze activity data from message or context."""
        health_data = context.get("health_data", {}) if context else {}
        
        steps = health_data.get("steps", 0)
        active_energy = health_data.get("active_energy", 0)
        exercise_minutes = health_data.get("exercise_minutes", 0)
        
        steps_status = "ä¼˜ç§€" if steps >= 10000 else "è‰¯å¥½" if steps >= 8000 else "éœ€æ”¹è¿›"
        energy_status = "ä¼˜ç§€" if active_energy >= 500 else "è‰¯å¥½" if active_energy >= 400 else "éœ€æ”¹è¿›"
        
        return {
            "steps": steps,
            "steps_status": steps_status,
            "active_energy": active_energy,
            "energy_status": energy_status,
            "exercise_minutes": exercise_minutes,
            "overall_assessment": "ç»§ç»­ä¿æŒ" if steps >= 8000 else "åŠ æ²¹åŠªåŠ›"
        }

    async def _generate_exercise_plan(
        self,
        analysis: Dict[str, Any],
        context: Optional[Dict[str, Any]]
    ) -> list:
        """Generate exercise recommendations."""
        recommendations = []
        
        if analysis["steps"] < 8000:
            recommendations.append("å°è¯•å¢åŠ æ­¥æ•°ï¼šé¥­åæ•£æ­¥15-20åˆ†é’Ÿå¯¹é™ä½è¡€ç³–ç‰¹åˆ«æœ‰æ•ˆ")
        
        if analysis["exercise_minutes"] < 30:
            recommendations.append("æ¯å¤©è‡³å°‘30åˆ†é’Ÿä¸­ç­‰å¼ºåº¦è¿åŠ¨ï¼ˆå¿«èµ°ã€æ¸¸æ³³ã€éª‘è½¦ï¼‰")
        
        recommendations.extend([
            "ç»“åˆåŠ›é‡è®­ç»ƒï¼šæ¯å‘¨2-3æ¬¡ï¼Œå¢å¼ºèƒ°å²›ç´ æ•æ„Ÿæ€§",
            "ä¿æŒè§„å¾‹ï¼šè¿åŠ¨çš„ä¸€è‡´æ€§æ¯”å¼ºåº¦æ›´é‡è¦",
            "ç›‘æ§å¿ƒç‡ï¼šä¿æŒåœ¨50-70%æœ€å¤§å¿ƒç‡èŒƒå›´å†…"
        ])
        
        return recommendations

    def _format_response(
        self,
        analysis: Dict[str, Any],
        recommendations: list
    ) -> str:
        """Format response for user."""
        response = f"""## è¿åŠ¨åˆ†æ

**æ­¥æ•°**: {analysis['steps']} æ­¥ ({analysis['steps_status']})
**æ´»åŠ¨èƒ½é‡**: {analysis['active_energy']} åƒå¡ ({analysis['energy_status']})
**è¿åŠ¨æ—¶é•¿**: {analysis['exercise_minutes']} åˆ†é’Ÿ

**æ€»ä½“è¯„ä¼°**: {analysis['overall_assessment']}

## è¿åŠ¨å»ºè®®

"""
        for i, rec in enumerate(recommendations, 1):
            response += f"{i}. {rec}\n"
        
        response += "\nğŸƒ è¿åŠ¨æ˜¯æ”¹å–„èƒ°å²›ç´ æŠµæŠ—çš„æœ€ä½³å¤©ç„¶è¯ç‰©ï¼æ¯ä¸€æ­¥éƒ½å¾ˆé‡è¦ï¼\n"
        response += "\n_æç¤ºï¼šé…ç½® LLM API åå¯è·å¾—æ›´ä¸ªæ€§åŒ–çš„è¿åŠ¨åˆ†æå’Œå»ºè®®ã€‚_"
        
        return response
